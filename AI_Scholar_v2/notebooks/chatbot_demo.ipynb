{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# chatbot_demo.ipynb\n",
        "\n",
        "# Install necessary libraries if you haven't already"
      ],
      "metadata": {
        "id": "7FStDpQzgj9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain transformers llama-cpp-python faiss-cpu\n",
        "\n",
        "from src.data_ingestion import pdf_to_text\n",
        "from src.retriever import create_vector_store, get_retriever\n",
        "from src.generator import load_llama3_model, generate_response\n",
        "from src.rag_chain import create_qa_chain"
      ],
      "metadata": {
        "id": "AQNVBF4Jgl4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the text data and create the vector store\n"
      ],
      "metadata": {
        "id": "kXuFxrlqgr62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_folder = '../data/pdfs'\n",
        "texts = pdf_to_text(pdf_folder)\n",
        "vector_store = create_vector_store(texts)\n",
        "retriever = get_retriever(vector_store)\n"
      ],
      "metadata": {
        "id": "6dGnrTvhgsnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the fine-tuned Llama3 model (or the base model if not fine-tuned)\n"
      ],
      "metadata": {
        "id": "od7XPz2TgyJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"./fine_tuned_model\"  # Use fine-tuned model\n",
        "model, tokenizer = load_llama3_model(model_name)"
      ],
      "metadata": {
        "id": "x33C4iVWg3Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the QA chain\n"
      ],
      "metadata": {
        "id": "KI7vxA8lg5kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = create_qa_chain(retriever, model, tokenizer)\n"
      ],
      "metadata": {
        "id": "C4kTk5_Cg6uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ask questions using the chatbot\n"
      ],
      "metadata": {
        "id": "78WJ_DOLg7-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question(query):\n",
        "    response = qa_chain.run(query)\n",
        "    return response\n",
        "\n"
      ],
      "metadata": {
        "id": "KQlBrJUHg9Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example interactions\n"
      ],
      "metadata": {
        "id": "6rbLT7Zqg_sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Chatbot initialized. You can start asking questions!\")\n",
        "\n",
        "questions = [\n",
        "    \"What is the focus of the research on AI in these papers?\",\n",
        "    \"Summarize the findings on deep learning techniques.\",\n",
        "    \"How do these papers approach the topic of climate change?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    print(f\"\\nQuestion: {question}\")\n",
        "    print(f\"Answer: {ask_question(question)}\")"
      ],
      "metadata": {
        "id": "pflAfdFbhBrt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
